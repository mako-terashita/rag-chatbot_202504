# app_txt_loader.py

import os
from dotenv import load_dotenv
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

# .envã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
with open("Genetic_Deepreserch.txt", "r", encoding="utf-8") as f:
    full_text = f.read()

print("ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿è¾¼ã¿å®Œäº†")

# ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = splitter.create_documents([full_text])

# åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
db = FAISS.from_documents(docs, embeddings)

# ä¿å­˜
db.save_local("faiss_index")
print("âœ… FAISSãƒ™ã‚¯ãƒˆãƒ«DBã«ä¿å­˜å®Œäº†")