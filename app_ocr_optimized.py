import os
import pathlib
from dotenv import load_dotenv
from pdf2image import convert_from_path
import pytesseract
from langchain_openai import OpenAIEmbeddings  # æ–°ã—ã„æ§‹æ–‡
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.docstore.document import Document

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# ãƒ‘ã‚¹å®šç¾©
pdf_path = "data/Document_240323_143426.pdf"  # â†ã“ã“ã‚’ã‚ãªãŸã®PDFãƒ•ã‚¡ã‚¤ãƒ«åã«åˆã‚ã›ã¦å¤‰æ›´ï¼
index_dir = "faiss_index"

# ãƒ™ã‚¯ãƒˆãƒ«DBãŒæ—¢ã«ã‚ã‚‹ã‹ã©ã†ã‹ã§å‡¦ç†åˆ†å²
if pathlib.Path(index_dir).exists():
    print("ğŸš€ ä¿å­˜æ¸ˆã¿ã®ãƒ™ã‚¯ãƒˆãƒ«DBã‚’èª­ã¿è¾¼ã¿ã¾ã™...")
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    db = FAISS.load_local(index_dir, embeddings, allow_dangerous_deserialization=True)
else:
    print("ğŸ”„ PDFã‚’ç”»åƒã«å¤‰æ›ä¸­...")
    images = convert_from_path(pdf_path)

    print("ğŸ§  OCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­...")
    full_text = ""
    print("âœ… ç”»åƒã”ã¨ã®OCRãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ï¼š")
    for image in images:
        text = pytesseract.image_to_string(image, lang='eng')
        print("----- 1ãƒšãƒ¼ã‚¸åˆ†ã®ãƒ†ã‚­ã‚¹ãƒˆ -----")
        print(text)
        full_text += text

    print("ğŸ“„ OCRå…¨æ–‡ï¼ˆå…ˆé ­1000æ–‡å­—ï¼‰:\n", full_text[:1000])
    for page_num, image in enumerate(images):
        text = pytesseract.image_to_string(image)
        full_text += f"\n--- Page {page_num + 1} ---\n{text}"
    print("ğŸ“„ OCRãƒ†ã‚­ã‚¹ãƒˆçµæœã®ä¸€éƒ¨:\n", full_text[:1000])

    print("ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ä¸­...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = text_splitter.split_documents([Document(page_content=full_text)])

    print("ğŸ” ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    db = FAISS.from_documents(docs, embeddings)

    print("ğŸ’¾ ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä¿å­˜ä¸­...")
    db.save_local(index_dir)

# QAãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰
print("âš™ï¸ QAãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ä¸­...")
retriever = db.as_retriever()
qa = RetrievalQA.from_chain_type(
    llm=OpenAI(temperature=0, openai_api_key=openai_api_key),
    retriever=retriever,
    chain_type="stuff"
)
print("âœ… ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰å®Œäº†ã€‚æ—¥æœ¬èªã§è³ªå•ã—ã¦ãã ã•ã„ï¼ˆçµ‚äº†ã™ã‚‹ã«ã¯ 'exit'ï¼‰")

# è³ªå•ãƒ«ãƒ¼ãƒ—
while True:
    query = input("ğŸ—¨ è³ªå•: ")
    if query.lower() in ["exit", "quit", "çµ‚äº†"]:
        print("ğŸ‘‹ çµ‚äº†ã—ã¾ã™ã€‚")
        break
    answer = qa.run(f"æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è³ªå•: {query}")
    print(f"ğŸ’¬ å›ç­”: {answer}\n")
