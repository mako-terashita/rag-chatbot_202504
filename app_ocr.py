import os
from dotenv import load_dotenv
from pdf2image import convert_from_path
import pytesseract
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.docstore.document import Document

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# PDFã‚’ç”»åƒã«å¤‰æ›
pdf_path = "data/Document_240323_143426.pdf"
print("ğŸ”„ PDFã‚’ç”»åƒã«å¤‰æ›ä¸­...")
images = convert_from_path(pdf_path)

# OCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
print("ğŸ§  OCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­...")
full_text = ""
for page_num, image in enumerate(images):
    text = pytesseract.image_to_string(image)
    full_text += f"\n--- Page {page_num + 1} ---\n{text}"

# ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = text_splitter.split_documents([Document(page_content=full_text)])

# ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
print("ğŸ” ãƒ™ã‚¯ãƒˆãƒ«DBä½œæˆä¸­...")
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
db = FAISS.from_documents(docs, embeddings)
retriever = db.as_retriever()

# RAG QA ãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
qa = RetrievalQA.from_chain_type(
    llm=OpenAI(temperature=0, openai_api_key=openai_api_key),
    retriever=retriever,
    chain_type="stuff"
)

print("âœ… æº–å‚™å®Œäº†ï¼æ—¥æœ¬èªã§è³ªå•ã—ã¦ãã ã•ã„ï¼ˆçµ‚äº†ã™ã‚‹ã«ã¯ 'exit'ï¼‰")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®å¯¾è©±ãƒ«ãƒ¼ãƒ—
while True:
    query = input("ğŸ—¨ è³ªå•: ")
    if query.lower() in ["exit", "quit", "çµ‚äº†"]:
        print("ğŸ‘‹ çµ‚äº†ã—ã¾ã™ã€‚")
        break
    answer = qa.run(f"æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è³ªå•: {query}")
    print(f"ğŸ’¬ å›ç­”: {answer}\n")
